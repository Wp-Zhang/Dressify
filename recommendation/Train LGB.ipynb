{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code modified from from my [another project](https://github.com/Wp-Zhang/H-M-Fashion-RecSys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./\") # path to the `src`` folder\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.metrics import map_at_k, hr_at_k, recall_at_k\n",
    "from src.retrieval.rules import (\n",
    "    OrderHistory,\n",
    "    ItemPair,\n",
    "    TimeHistory,\n",
    "    ItemCF\n",
    ")\n",
    "from src.retrieval.collector import RuleCollector\n",
    "from src.utils import calc_valid_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./\")\n",
    "model_dir = Path(\"./models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_WEEK_NUM = 4\n",
    "WEEK_NUM = TRAIN_WEEK_NUM + 2\n",
    "\n",
    "VERSION_NAME = \"Deploy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(data_dir/\"interim\"/VERSION_NAME):\n",
    "    os.mkdir(data_dir/\"interim\"/VERSION_NAME)\n",
    "if not os.path.exists(data_dir/\"processed\"/VERSION_NAME):\n",
    "    os.mkdir(data_dir/\"processed\"/VERSION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = pd.read_csv('orders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del order['article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>price</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>3</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1</td>\n",
       "      <td>663713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>3</td>\n",
       "      <td>17.99</td>\n",
       "      <td>1</td>\n",
       "      <td>541518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>8</td>\n",
       "      <td>8.99</td>\n",
       "      <td>2</td>\n",
       "      <td>505221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>8</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2</td>\n",
       "      <td>685687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>8</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2</td>\n",
       "      <td>685687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat  customer_id  price  order_id  product_code\n",
       "0  2018-09-20            3  29.99         1        663713\n",
       "1  2018-09-20            3  17.99         1        541518\n",
       "2  2018-09-20            8   8.99         2        505221\n",
       "3  2018-09-20            8   9.99         2        685687\n",
       "4  2018-09-20            8   9.99         2        685687"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "order['t_dat'] = pd.to_datetime(order['t_dat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(\n",
    "        trans_data: pd.DataFrame,\n",
    "        train_end_date: str,\n",
    "        valid_end_date: str,\n",
    "        item_id: str = \"product_code\",\n",
    "    ):\n",
    "        if item_id not in trans_data.columns:\n",
    "            raise KeyError(f\"{item_id} is not one of the columns\")\n",
    "\n",
    "        train_set = trans_data.loc[trans_data[\"t_dat\"] < train_end_date]\n",
    "        valid_set = trans_data.loc[\n",
    "            (train_end_date <= trans_data[\"t_dat\"])\n",
    "            & (trans_data[\"t_dat\"] < valid_end_date)\n",
    "        ]\n",
    "        valid_set = (\n",
    "            valid_set.groupby([\"customer_id\"])[item_id].apply(list).reset_index()\n",
    "        )\n",
    "\n",
    "        return train_set, valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1: [2020-09-16, 2020-09-23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  25%|██▌       | 1/4 [00:20<01:00, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.03642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  50%|█████     | 2/4 [00:30<00:29, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01468\n",
      "Positive rate: 0.02520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules: 100%|██████████| 4/4 [01:40<00:00, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 2: [2020-09-09, 2020-09-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  25%|██▌       | 1/4 [00:18<00:56, 18.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.03661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  50%|█████     | 2/4 [00:29<00:27, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01584\n",
      "Positive rate: 0.02530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules: 100%|██████████| 4/4 [01:44<00:00, 26.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 3: [2020-09-02, 2020-09-09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  25%|██▌       | 1/4 [00:19<00:59, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.03393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  50%|█████     | 2/4 [00:31<00:29, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  75%|███████▌  | 3/4 [01:54<00:45, 45.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.02410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules: 100%|██████████| 4/4 [01:54<00:00, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 4: [2020-08-26, 2020-09-02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  25%|██▌       | 1/4 [00:18<00:55, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.03033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  50%|█████     | 2/4 [00:29<00:28, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  75%|███████▌  | 3/4 [01:54<00:46, 46.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.02173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules: 100%|██████████| 4/4 [01:55<00:00, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 5: [2020-08-19, 2020-08-26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  25%|██▌       | 1/4 [00:18<00:56, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.03284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  50%|█████     | 2/4 [00:29<00:28, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules:  75%|███████▌  | 3/4 [01:54<00:46, 46.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.02109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve items by rules: 100%|██████████| 4/4 [01:54<00:00, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate: 0.01174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# * WEEK_NUM = 0: test\n",
    "# * WEEK_NUM = 1: valid\n",
    "# * WEEK_NUM > 1: train\n",
    "for week in range(1,WEEK_NUM):\n",
    "    # * use sliding window to generate candidates\n",
    "    trans = order\n",
    "\n",
    "    start_date, end_date = calc_valid_date(week)\n",
    "    print(f\"Week {week}: [{start_date}, {end_date})\")\n",
    "    \n",
    "    train, valid = split_data(trans, start_date, end_date)\n",
    "\n",
    "    last_week = train[train['t_dat']>train['t_dat'].max()-pd.Timedelta(days=7)]\n",
    "    last_2week = train[train['t_dat']>train['t_dat'].max()-pd.Timedelta(days=14)]\n",
    "    last_80day = train[train['t_dat']>train['t_dat'].max()-pd.Timedelta(days=80)]\n",
    "\n",
    "    if week != 0:\n",
    "        customer_list = valid[\"customer_id\"].values\n",
    "\n",
    "    # * ========================== Retrieval Strategies ==========================\n",
    "\n",
    "    candidates = RuleCollector().collect(\n",
    "        week_num = week,\n",
    "        trans_df = trans,\n",
    "        customer_list=customer_list,\n",
    "        rules=[\n",
    "            OrderHistory(train, days=7, n=8, name=1),\n",
    "            ItemPair(OrderHistory(train, days=7, n=8).retrieve(), name=2),\n",
    "            ItemCF(last_80day, last_2week, top_k=8, name=3),\n",
    "            TimeHistory(customer_list, last_week, n=8, name=4),\n",
    "        ],\n",
    "        norm=False,\n",
    "        min_pos_rate=0,\n",
    "        compress=False,\n",
    "    )\n",
    "\n",
    "    candidates.to_parquet(data_dir/\"interim\"/VERSION_NAME/f\"week{week}_candidate.pqt\")\n",
    "    valid.to_parquet(data_dir/\"processed\"/VERSION_NAME/f\"week{week}_label.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0991061642860725"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = candidates.drop_duplicates(['customer_id','product_code']).groupby('customer_id')['product_code'].apply(list).reset_index()\n",
    "label = valid.merge(pred.rename({'product_code':'pred'},axis=1),on='customer_id',how='left')\n",
    "recall_at_k(label['product_code'], label['pred'], k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = calc_valid_date(1)\n",
    "train, valid = split_data(order, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = order[order['t_dat']>=start_date][order['t_dat']<=end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = ItemPair(df)\n",
    "pair = ip._get_freq_pair()\n",
    "del pair['count']\n",
    "pair['method'] = 2\n",
    "pair.to_csv('./recall_item_pair.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale = df.drop_duplicates(['customer_id','product_code']).groupby('product_code').size().reset_index(name='score')\n",
    "sale = sale.sort_values(by='score',ascending=False).head(8)\n",
    "sale['method'] = 4\n",
    "sale.to_csv('./recall_sale.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_2week = order[order['t_dat']>order['t_dat'].max()-pd.Timedelta(days=14)]\n",
    "last_80day = order[order['t_dat']>order['t_dat'].max()-pd.Timedelta(days=80)]\n",
    "cf = ItemCF(last_80day, last_2week)\n",
    "pred_next, pred_score = cf._item_cf(8)\n",
    "\n",
    "df_l = []\n",
    "for pid in tqdm(pred_next):\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['pair'] = pred_next[pid]\n",
    "    tmp['score'] = pred_score[pid]\n",
    "    tmp['product_code'] = pid\n",
    "    df_l.append(tmp)\n",
    "\n",
    "cf_df = pd.concat(df_l, ignore_index=True)\n",
    "cf_df['method'] = 3\n",
    "cf_df.to_csv('./recall_cf.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148761, 4)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate week number\n",
    "order['week'] = (pd.to_datetime('2020-09-29') - pd.to_datetime(order['t_dat'])).dt.days // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = order.drop_duplicates(['product_code','week'])[['product_code','week']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_sale = order.groupby(['product_code','week']).size().reset_index(name=\"week_sale\")\n",
    "full_sale = order.groupby(['product_code']).size().reset_index(name=\"full_sale\")\n",
    "feature_df = feature_df.merge(week_sale, on=['product_code','week'], how='left')\n",
    "feature_df = feature_df.merge(full_sale, on=['product_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['week_sale_ratio'] = feature_df['week_sale'] / feature_df['full_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>week</th>\n",
       "      <th>week_sale</th>\n",
       "      <th>full_sale</th>\n",
       "      <th>week_sale_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663713</td>\n",
       "      <td>105</td>\n",
       "      <td>40</td>\n",
       "      <td>633</td>\n",
       "      <td>0.063191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>541518</td>\n",
       "      <td>105</td>\n",
       "      <td>94</td>\n",
       "      <td>8161</td>\n",
       "      <td>0.011518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>505221</td>\n",
       "      <td>105</td>\n",
       "      <td>38</td>\n",
       "      <td>127</td>\n",
       "      <td>0.299213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>685687</td>\n",
       "      <td>105</td>\n",
       "      <td>4424</td>\n",
       "      <td>6613</td>\n",
       "      <td>0.668985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>688873</td>\n",
       "      <td>105</td>\n",
       "      <td>1624</td>\n",
       "      <td>37368</td>\n",
       "      <td>0.043460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_code  week  week_sale  full_sale  week_sale_ratio\n",
       "0        663713   105         40        633         0.063191\n",
       "1        541518   105         94       8161         0.011518\n",
       "2        505221   105         38        127         0.299213\n",
       "3        685687   105       4424       6613         0.668985\n",
       "4        688873   105       1624      37368         0.043460"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = pd.read_json('./product.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"product_type_name\",\n",
    "    \"garment_group_name\",\n",
    "    \"section_name\",\n",
    "    \"index_group_name\",\n",
    "]\n",
    "for col in cols:\n",
    "    product[col] = product[col].map(dict(zip(product[col].unique(),range(product[col].nunique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_cols = [\n",
    "        \"product_code\",\n",
    "        \"price\",\n",
    "        \"product_type_name\",\n",
    "        \"garment_group_name\",\n",
    "        \"section_name\",\n",
    "        \"index_group_name\",\n",
    "    ]\n",
    "\n",
    "item_feats = week_sale[week_sale['week']==1][['product_code','week_sale']]\n",
    "item_feats = item_feats.merge(full_sale, on=['product_code'], how='right')\n",
    "item_feats = item_feats.fillna(0)\n",
    "item_feats['week_sale_ratio'] = item_feats['week_sale'] / item_feats['full_sale']\n",
    "item_feats['product_code'] = item_feats['product_code'].astype(int)\n",
    "item_feats = item_feats.merge(product[prod_cols], on='product_code',how='left')\n",
    "item_feats.to_csv('./item_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1703852/1703852 [00:45<00:00, 37190.51it/s]\n",
      "100%|██████████| 1826720/1826720 [00:49<00:00, 36540.27it/s]\n",
      "100%|██████████| 1882870/1882870 [00:51<00:00, 36212.94it/s]\n",
      "100%|██████████| 1948812/1948812 [00:55<00:00, 34834.76it/s]\n",
      "100%|██████████| 1848024/1848024 [00:51<00:00, 35679.97it/s]\n",
      "100%|██████████| 5/5 [05:04<00:00, 60.83s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1, WEEK_NUM)):\n",
    "    candidate = pd.read_parquet(\n",
    "        data_dir / \"interim\" / VERSION_NAME / f\"week{i}_candidate.pqt\"\n",
    "    )\n",
    "    label = pd.read_parquet(data_dir/\"processed\"/VERSION_NAME/f\"week{i}_label.pqt\")    \n",
    "\n",
    "    candidate[\"week\"] = i\n",
    "\n",
    "    candidate = candidate.merge(feature_df, on=[\"product_code\", \"week\"], how=\"left\")\n",
    "    candidate = candidate.merge(label.rename({\"product_code\":'label'},axis=1),on='customer_id',how='right')\n",
    "    candidate = candidate.merge(product[prod_cols],on='product_code',how='left')\n",
    "    candidate['label'] = candidate.progress_apply(lambda x:x['product_code'] in x['label'], axis=1)\n",
    "\n",
    "    candidate.to_parquet(\n",
    "        data_dir / \"processed\" / VERSION_NAME / f\"week{i}_candidate.pqt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = {}\n",
    "labels = {}\n",
    "for i in tqdm(range(1, WEEK_NUM)):\n",
    "    candidates[i] = pd.read_parquet(data_dir/\"processed\"/VERSION_NAME/f\"week{i}_candidate.pqt\")\n",
    "    labels[i] = pd.read_parquet(data_dir/\"processed\"/VERSION_NAME/f\"week{i}_label.pqt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\n",
    "    x\n",
    "    for x in candidates[1].columns\n",
    "    if x\n",
    "    not in [\n",
    "        \"label\",\n",
    "        \"t_dat\",\n",
    "        'week',\n",
    "        'customer_id'\n",
    "    ]\n",
    "]\n",
    "cat_features = [\n",
    "    \"method\",\n",
    "    # \"customer_id\",\n",
    "    \"product_code\",\n",
    "    \"product_type_name\",\n",
    "    \"garment_group_name\",\n",
    "    \"section_name\",\n",
    "    \"index_group_name\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([candidates[i] for i in range(1, WEEK_NUM)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = full_data.loc[full_data['week']>1]\n",
    "valid = full_data.loc[full_data['week']==1]\n",
    "\n",
    "del full_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\", # \"lambdarank\"\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"metric\": \"auc\", # \"map\"\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 128,\n",
    "    \"learning_rate\": 0.03,\n",
    "\n",
    "    \"verbose\": -1,\n",
    "    \"eval_at\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rank_model(train, valid, train_group, valid_group):\n",
    "\n",
    "    train_set = lgb.Dataset(\n",
    "        data=train[feats],\n",
    "        label=train[\"label\"],\n",
    "        group=train_group,\n",
    "        feature_name=feats,\n",
    "        categorical_feature=cat_features,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    valid_set = lgb.Dataset(\n",
    "        data=valid[feats],\n",
    "        label=valid[\"label\"],\n",
    "        group=valid_group,\n",
    "        feature_name=feats,\n",
    "        categorical_feature=cat_features,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    ranker = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_set],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=20,\n",
    "    )\n",
    "    ranker.save_model(\n",
    "        model_dir / f\"lgb_ranker.model\",\n",
    "        num_iteration=ranker.best_iteration,\n",
    "    )\n",
    "    return ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_model(train, valid):\n",
    "\n",
    "    train_set = lgb.Dataset(\n",
    "        data=train[feats],\n",
    "        label=train[\"label\"],\n",
    "        feature_name=feats,\n",
    "        categorical_feature=cat_features,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    valid_set = lgb.Dataset(\n",
    "        data=valid[feats],\n",
    "        label=valid[\"label\"],\n",
    "        feature_name=feats,\n",
    "        categorical_feature=cat_features,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    ranker = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=100,\n",
    "        valid_sets=[valid_set],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=10,\n",
    "    )\n",
    "    ranker.save_model(\n",
    "        model_dir / f\"lgb_binary.model\",\n",
    "        num_iteration=ranker.best_iteration,\n",
    "    )\n",
    "    return ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positive rate: 0.02048524823930856\n"
     ]
    }
   ],
   "source": [
    "print(\"Train positive rate:\", train.label.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"week\", \"customer_id\"], ascending=True).reset_index(drop=True)\n",
    "valid = valid.sort_values(by=[\"customer_id\"], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group = train[[\"customer_id\", \"product_code\", \"week\"]]\n",
    "train_group = train_group.astype(\"int32\")  # * convert to int to avoid `0` in groupby count result\n",
    "train_group = (train_group.groupby([\"week\", \"customer_id\"]).size().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_group = valid[[\"customer_id\", \"product_code\"]]\n",
    "valid_group = valid_group.astype(\"int32\")  # * convert to int to avoid `0` in groupby count result\n",
    "valid_group = valid_group.groupby([\"customer_id\"]).size().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's auc: 0.720171\n",
      "[20]\tvalid_0's auc: 0.724597\n",
      "[30]\tvalid_0's auc: 0.726479\n",
      "[40]\tvalid_0's auc: 0.72779\n",
      "[50]\tvalid_0's auc: 0.728788\n",
      "[60]\tvalid_0's auc: 0.729495\n",
      "[70]\tvalid_0's auc: 0.729859\n",
      "[80]\tvalid_0's auc: 0.730414\n",
      "[90]\tvalid_0's auc: 0.730779\n",
      "[100]\tvalid_0's auc: 0.7311\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.731131\n"
     ]
    }
   ],
   "source": [
    "# ranker = train_rank_model(train, valid, train_group, valid_group)\n",
    "ranker = train_binary_model(train[feats+['label']], valid[feats+['label']])\n",
    "# 0.728776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_candidates = valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ranker, candidates, batch_size = 5_000_000):\n",
    "    probs = np.zeros(candidates.shape[0])\n",
    "    for batch in range(0, candidates.shape[0], batch_size):\n",
    "        outputs = ranker.predict(candidates.loc[batch : batch + batch_size - 1, feats])\n",
    "        probs[batch : batch + batch_size] = outputs\n",
    "    candidates[\"prob\"] = probs\n",
    "    pred_lgb = candidates[['customer_id','product_code','prob']]\n",
    "    pred_lgb = pred_lgb.sort_values(by=[\"customer_id\",\"prob\"], ascending=False).reset_index(drop=True)\n",
    "    pred_lgb.rename(columns={'product_code':'prediction'}, inplace=True)\n",
    "    pred_lgb = pred_lgb.drop_duplicates(['customer_id', 'prediction'], keep='first')\n",
    "    pred_lgb['customer_id'] = pred_lgb['customer_id'].astype(int)\n",
    "    pred_lgb = pred_lgb.groupby(\"customer_id\")[\"prediction\"].progress_apply(list).reset_index()\n",
    "    return pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68952/68952 [00:01<00:00, 35582.41it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = predict(ranker, val_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels[1]\n",
    "label = pd.merge(label, pred, on=\"customer_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03894939797089119"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_at_k(label[\"product_code\"], label[\"prediction\"], k=4)\n",
    "\n",
    "# 0.03933704686674143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09276867095395626"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(label[\"product_code\"], label[\"prediction\"], k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.Booster(model_file='./models/lgb_binary.model')\n",
    "mlflow.lightgbm.save_model(model, './models/mlflow_lgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('handyrec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eee4fdb9ca52ce5d5f0a2a1c2a1d0a4896d6b735579ddf3d9c0ee93e21b97ca8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
